{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKpRP1XSYYmB",
        "outputId": "cb8a5ad3-6296-49df-832f-7e539b303e94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'VELMA'...\n",
            "remote: Enumerating objects: 137, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 137 (delta 14), reused 24 (delta 10), pack-reused 104 (from 1)\u001b[K\n",
            "Receiving objects: 100% (137/137), 101.75 MiB | 8.24 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n",
            "Updating files: 100% (78/78), done.\n",
            "/content/VELMA\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/raphael-sch/VELMA.git\n",
        "%cd VELMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IKJCCEt2t1S",
        "outputId": "30465e2c-6b4c-4718-d8f4-589567ae64af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HE5zwMqZpBYI"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import requests\n",
        "import requests\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import math\n",
        "import html\n",
        "import re\n",
        "import cv2\n",
        "import numpy as np\n",
        "import imageio\n",
        "import os\n",
        "import csv\n",
        "import time\n",
        "import json\n",
        "import ast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5QVmHYsKjLD"
      },
      "source": [
        "CALL DATASET TO GET NAVIGATION TEXT, PANOID AND START_HEADING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wzS2kULT6Oxh",
        "outputId": "81421b43-66bc-44a8-c57e-1045bb5122a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    city  route_id                pre_pano       pre_heading  \\\n",
            "0    nyc      4754  wOd2XDb0Js4uUZB1UHEmjA  121.872246611971   \n",
            "1    nyc      7046  aqXt8prWxtLqaEQ0jYiRRg  264.463047862252   \n",
            "2    nyc      2112  JJf0XkoQciZCxTHEpcAQpw  244.488995003821   \n",
            "3    nyc     11882  S3xnRu6DiGStxOnDGpWHiQ  27.7760044566822   \n",
            "4    nyc     11229  muETW50Yu_HmaqF8zdbAnA  57.3646240080053   \n",
            "..   ...       ...                     ...               ...   \n",
            "795  nyc       954  V25zegZIuyAWUEOL2IXvHg  269.056696086243   \n",
            "796  nyc     10711  XQHHEmvtX9FRig5J0plgQw  125.526212921869   \n",
            "797  nyc      1925  r4kDRfQNNTzuWcGby-1-3Q  209.557677264822   \n",
            "798  nyc      2349  4tnXHMwuyLIxgZzLGBvGEQ  222.795579308865   \n",
            "799  nyc      3970  7pgoQV3e_mlT_TtIJWR2CA  311.416499086761   \n",
            "\n",
            "              pre_pitch                                        pre_center  \\\n",
            "0    0.0887000690027548   {\"x\":0.4188118811881188,\"y\":0.5903225806451613}   \n",
            "1     -12.5421981054401  {\"x\":0.2584158415841584,\"y\":0.22258064516129034}   \n",
            "2      4.47391857723487    {\"x\":0.3504950495049505,\"y\":0.532258064516129}   \n",
            "3     -9.87780792735296   {\"x\":0.698019801980198,\"y\":0.49032258064516127}   \n",
            "4     -11.4870285513346   {\"x\":0.3722772277227723,\"y\":0.4064516129032258}   \n",
            "..                  ...                                               ...   \n",
            "795    15.8610605202697                  {\"x\":0.5267326732673268,\"y\":0.6}   \n",
            "796    2.72651590764615    {\"x\":0.6079207920792079,\"y\":0.567741935483871}   \n",
            "797   -12.0568378071975   {\"x\":0.3435643564356436,\"y\":0.3709677419354839}   \n",
            "798   -10.3798800946198   {\"x\":0.3891089108910891,\"y\":0.3032258064516129}   \n",
            "799   -9.13472309092178   {\"x\":0.5366336633663367,\"y\":0.5419354838709678}   \n",
            "\n",
            "    pre_original_width pre_original_height               post_pano  \\\n",
            "0                 1010                 310  4IkJdnLVvtp0JYZ5AKE2Hw   \n",
            "1                 1010                 310  HI-ZeAfkDSHOSFbBoeLPoQ   \n",
            "2                 1010                 310  ghYA4iprEqZs5VoMFWREaQ   \n",
            "3                 1010                 310  keH4b21r3UFDo8X68Zsx6Q   \n",
            "4                 1010                 310  LfOa_VjmPptuYljm_M6iBQ   \n",
            "..                 ...                 ...                     ...   \n",
            "795               1010                 310  q5GjQplyHFK50zKgnwcd9w   \n",
            "796               1010                 310  nAJckodRLMsIvkYOu4j5eg   \n",
            "797               1010                 310  0mjgvL96n34bK4cVuNPwqA   \n",
            "798               1010                 310  AFoioUooA9CoLxwHkh7ZxA   \n",
            "799               1010                 310  yy39bCMeK0ZHblVZNt1AfA   \n",
            "\n",
            "         post_heading  ...                                    navigation_text  \\\n",
            "0    111.750597659154  ...  Turn so that the trees are to your left. At th...   \n",
            "1    264.463047862252  ...  Orient yourself so that the intersections stop...   \n",
            "2    292.837184964576  ...  heading the same direction where the school bu...   \n",
            "3    11.6156338206047  ...  Going against traffic, go through the next two...   \n",
            "4    146.032548754184  ...  Turn so the green wall is to your right. Go th...   \n",
            "..                ...  ...                                                ...   \n",
            "795  294.127012175171  ...  Orient yourself so the sea is on the left and ...   \n",
            "796  125.526212921869  ...  Turn so the parking lot is on your right. Go s...   \n",
            "797   269.41966869227  ...  Turn so the bushes and trees are on your left,...   \n",
            "798               270  ...  Follow the traffic direction heading to the in...   \n",
            "799   256.45223591561  ...  Position yourself so you're moving with the fl...   \n",
            "\n",
            "                                      td_location_text  \\\n",
            "0    At the first intersection, turn left and stop....   \n",
            "1    . In the fenced area to the right should be a ...   \n",
            "2    next to the motorcycles on the walkway there i...   \n",
            "3     the bus shelter on the left, and can see a pa...   \n",
            "4     a line of bikes parked on the right. At the e...   \n",
            "..                                                 ...   \n",
            "795   a yellow shaped sign and a green rectangle sh...   \n",
            "796  Touchdown is in the middle of the red sign wit...   \n",
            "797  On your right is a red shopping cart. Touchdow...   \n",
            "798  on the right side you will see an orange/white...   \n",
            "799  and look to your left. There is a blue mailbox...   \n",
            "\n",
            "                                             full_text  \\\n",
            "0    Turn so that the trees are to your left.  At t...   \n",
            "1    Orient yourself so that the intersections stop...   \n",
            "2    heading the same direction where the school bu...   \n",
            "3    Going against traffic, go through the next two...   \n",
            "4    Turn so the green wall is to your right. Go th...   \n",
            "..                                                 ...   \n",
            "795  Orient yourself so the sea is on the left and ...   \n",
            "796  Turn so the parking lot is on your right. Go s...   \n",
            "797  Turn so the bushes and trees are on your left,...   \n",
            "798  Follow the traffic direction heading to the in...   \n",
            "799  Position yourself so you're moving with the fl...   \n",
            "\n",
            "                      elapsed failure_stats num_finished  \\\n",
            "0    {\"minute\":2,\"second\":54}             0            1   \n",
            "1    {\"minute\":4,\"second\":38}             0            1   \n",
            "2    {\"minute\":8,\"second\":27}             1            1   \n",
            "3    {\"minute\":9,\"second\":40}             0            1   \n",
            "4    {\"minute\":6,\"second\":15}             2            1   \n",
            "..                        ...           ...          ...   \n",
            "795  {\"minute\":3,\"second\":50}             0            1   \n",
            "796  {\"minute\":5,\"second\":35}             1            1   \n",
            "797  {\"minute\":2,\"second\":32}             0            1   \n",
            "798   {\"minute\":6,\"second\":0}             2            1   \n",
            "799  {\"minute\":5,\"second\":28}             0            1   \n",
            "\n",
            "                                         route_panoids start_heading  \\\n",
            "0    [pGD9GXAZChwjjq_1LMYp-Q, Ux3RvP7kPkhD9DBivH65F...           0.0   \n",
            "1    [hi77pLZx-xH-OkgZfYrB0w, 9KA4V3aNRfML9pe79Uklv...           0.0   \n",
            "2    [LEWUv61s6ncbpe3O_ZKGYQ, RxisJ0wt5_0FdAyKXVyp2...           0.0   \n",
            "3    [zSaCHetTGDU_QAVrA4H4iA, p2iCJyXSlVFYC8znuA8-y...           0.0   \n",
            "4    [sr32IUe-z0zV1bUEfh9-aA, kmq8rsCDK7gXmuQh3zEBw...           0.0   \n",
            "..                                                 ...           ...   \n",
            "795  [V6AYAQ-qLN5Av6dVdhlUYQ, ePlCma5giZH-AX5cmeutU...           0.0   \n",
            "796  [fqzze35PanGXtxkekmpvEg, nN_TCQCOrWO638XM529G0...           0.0   \n",
            "797  [s2w9zE7gYNnSZPLwYULSnA, Z6luJodrXk-khI8DcUel7...           0.0   \n",
            "798  [Wvr6J4v-DrRAndz0Xo8EdQ, xlM2Kq6EnzFgwjB7d0yhA...           0.0   \n",
            "799  [8Xmw6k7dvhUMDtNvPF5s3w, P0P1pGnI99tm26q1bvz39...           0.0   \n",
            "\n",
            "    end_heading                                     follower_stats  \n",
            "0    111.750598  [{'follower_elapsed': '{\"minute\":0,\"second\":41...  \n",
            "1    264.463048  [{'follower_elapsed': '{\"minute\":1,\"second\":30...  \n",
            "2    269.022871  [{'follower_elapsed': '{\"minute\":3,\"second\":29...  \n",
            "3     11.615634  [{'follower_elapsed': '{\"minute\":2,\"second\":21...  \n",
            "4     79.739653  [{'follower_elapsed': '{\"minute\":1,\"second\":8}...  \n",
            "..          ...                                                ...  \n",
            "795  269.056696  [{'follower_elapsed': '{\"minute\":4,\"second\":3}...  \n",
            "796  125.526213  [{'follower_elapsed': '{\"minute\":0,\"second\":37...  \n",
            "797  218.098826  [{'follower_elapsed': '{\"minute\":1,\"second\":53...  \n",
            "798  222.795579  [{'follower_elapsed': '{\"minute\":1,\"second\":21...  \n",
            "799  256.452236  [{'follower_elapsed': '{\"minute\":1,\"second\":23...  \n",
            "\n",
            "[800 rows x 33 columns]\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'id'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'id'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-caa885526c48>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# If you need to access the length of 'id' for each row in the DataFrame:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_length'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Print the DataFrame with the new column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'id'"
          ]
        }
      ],
      "source": [
        "# Path to your JSON file\n",
        "json_file = '/content/VELMA/datasets/touchdown_unseen/data/dev.json'\n",
        "\n",
        "routes = []\n",
        "\n",
        "# Load the JSON file and split the content by newlines\n",
        "with open(json_file, 'r') as file:\n",
        "    content = file.read()  # Read the file content\n",
        "\n",
        "    # Split by lines (assuming each line is a separate JSON object)\n",
        "    json_objects = content.strip().split('\\n')\n",
        "\n",
        "    # Parse each JSON object separately\n",
        "    for obj in json_objects:\n",
        "        try:\n",
        "            data = json.loads(obj)  # Parse each JSON object\n",
        "            routes.append(data)    # Append the parsed data to the list\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON object: {e}\")\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "df = pd.DataFrame(routes)\n",
        "\n",
        "# Print the DataFrame to check if everything is loaded correctly\n",
        "print(df)\n",
        "\n",
        "# If you need to access the length of 'id' for each row in the DataFrame:\n",
        "df['id_length'] = df['id'].astype(str).apply(len)\n",
        "\n",
        "# Print the DataFrame with the new column\n",
        "unique_id_count = df['instructions_id'].nunique()\n",
        "print(f\"Number of unique IDs: {unique_id_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKcS2c9VKukL"
      },
      "source": [
        "CALL 7 SHOT LEARNING IN CONTEXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-Zm48DNM1o8"
      },
      "outputs": [],
      "source": [
        "# Read the example learning text file\n",
        "sample_learning = '/content/7_shot_lmm.txt'\n",
        "with open(sample_learning, 'r') as file:\n",
        "    shot_learning = file.read().strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjXCH57QKzg3"
      },
      "source": [
        "PERFORM THE TEXT TO SEND THE REQUEST TO OPEN AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO8rI5ies9iR"
      },
      "outputs": [],
      "source": [
        "def structure(navigation_instruction, api_key, shot_learning):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "\n",
        "    # Correctly format the content for the prompt\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": (\n",
        "                f\"Convert this navigation instruction: '{navigation_instruction}' \"\n",
        "                \"into a data structure you must have (n) nodes and (n-1) edges to build a graph,\"\n",
        "                \"it is mandatory to start with a node (Starting point) and an edge (Forward), if there is not an spatial relationship,\"\n",
        "                \"each node must have its corresponding edge, except for the last one, intersections node usually have actions edges\"\n",
        "                \" if the node has no action, place (Forward). Uses just Forward, Left, Right for actions, and On the left,\"\n",
        "                \"and On the Right for spatial relationships, head to the right or head to the left means Forward,\"\n",
        "                \"landmarks with the word light, is represented by a intersection node,\"\n",
        "                \"always use the following examples to get just the graph structure without any additional details: \"\n",
        "                f\"'{shot_learning}'. Do not show the navigation instruction.\"\n",
        "            )\n",
        "            }\n",
        "        ],\n",
        "        \"max_tokens\": 300\n",
        "    }\n",
        "\n",
        "    # Make the API request\n",
        "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "\n",
        "    # Handle the response\n",
        "    if response.status_code == 200:\n",
        "        response_data = response.json()\n",
        "        if 'choices' in response_data and len(response_data['choices']) > 0:\n",
        "            data_structure = response_data['choices'][0]['message']['content'].strip()\n",
        "            return data_structure\n",
        "        else:\n",
        "            raise ValueError(\"Response does not contain valid choices data.\")\n",
        "    else:\n",
        "        raise Exception(f\"API request failed with status code {response.status_code}: {response.text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLMEHCYe_h02"
      },
      "source": [
        "New approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAvrL-B0_ano"
      },
      "outputs": [],
      "source": [
        "def structure(navigation_instruction, api_key, shot_learning):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "\n",
        "    # Correctly format the content for the prompt\n",
        "    payload = {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": (\n",
        "                    f\"Convert the given navigation instruction '{navigation_instruction}' into a graph data structure with (n) nodes and (n-1) edges. Follow these rules:\"\n",
        "                    \"- Start with a node labeled (Starting Point) and an edge labeled (Forward) if no spatial relationship is given.\"\n",
        "                    \"- Each node must correspond to an edge, except for the target location.\"\n",
        "                    \"- Nodes labeled (Intersection) must be decision points, with edges labeled (Right), (Left), or (Forward). Only (Right) or (Left) correspond to edges originating from (Intersection) nodes.\"\n",
        "                    \"- Landmarks must include spatial relationships like (On the right), (On the left,) or (Forward).\"\n",
        "                    \"- If a node has no explicit action, use (Forward).\"\n",
        "                    \"- Phrases like (Head to the right) or (Head to the left) are interpreted as (Forward).\"\n",
        "                    \"- Landmarks containing (light) or (junction) correspond to nodes labeled (Intersection).\"\n",
        "                    \"- The target location must be the final node.\"\n",
        "                    \"- For instructions specifying an (x) number of intersections, include (x) nodes labeled (Intersection).\"\n",
        "                    \"- Another intersection in instructions means label an (Intersection) node\"\n",
        "                    f\"- Use this example format for the graph structure without additional details: '{shot_learning}'\"\n",
        "                    \"Do not include the original navigation instruction in your output.\"\n",
        "\n",
        "                    )\n",
        "            }\n",
        "        ],\n",
        "        \"max_tokens\": 300\n",
        "    }\n",
        "\n",
        "    # Make the API request\n",
        "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "\n",
        "    # Handle the response\n",
        "    if response.status_code == 200:\n",
        "        response_data = response.json()\n",
        "        if 'choices' in response_data and len(response_data['choices']) > 0:\n",
        "            data_structure = response_data['choices'][0]['message']['content'].strip()\n",
        "            return data_structure\n",
        "        else:\n",
        "            raise ValueError(\"Response does not contain valid choices data.\")\n",
        "    else:\n",
        "        raise Exception(f\"API request failed with status code {response.status_code}: {response.text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngCeXnHsp3lS"
      },
      "source": [
        "Function to convert into a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zscSvP5p7Eh"
      },
      "outputs": [],
      "source": [
        "# Convert all non-serializable types to standard Python types\n",
        "def convert_to_standard_types(data):\n",
        "    if isinstance(data, dict):\n",
        "        return {key: convert_to_standard_types(value) for key, value in data.items()}\n",
        "    elif isinstance(data, list):\n",
        "        return [convert_to_standard_types(item) for item in data]\n",
        "    elif isinstance(data, np.integer):  # Handle numpy integer\n",
        "        return int(data)\n",
        "    elif isinstance(data, np.floating):  # Handle numpy float\n",
        "        return float(data)\n",
        "    else:\n",
        "        return data\n",
        "\n",
        "\n",
        "def clean_and_convert(raw_data):\n",
        "    # Clean the raw data by removing any surrounding characters\n",
        "    raw_data = raw_data.strip().replace(\"```json\", \"\").replace(\"```\", \"\").replace(\"plaintext\", \"\").replace(\"{{\", \"{\").replace(\"}}\", \"}\").replace(\"{{{\", \"{\").replace(\"}}}\", \"}\")\n",
        "\n",
        "    # Step 1: Fix Nodes to ensure keys are quoted\n",
        "    cleaned_nodes = re.sub(r'(\\d+):', r'\"\\1\":', raw_data)\n",
        "\n",
        "    # Step 2: Fix Edges to ensure it is a list of dictionaries\n",
        "    cleaned_edges = re.sub(\n",
        "        r'\\{(\\d+),\\s*(\\d+),\\s*\"([^\"]+)\"\\}',\n",
        "        r'{\"from\": \\1, \"to\": \\2, \"action\": \"\\3\"}',\n",
        "        cleaned_nodes\n",
        "    )\n",
        "\n",
        "    # Step 3: Fix the Edges array\n",
        "    cleaned_edges = re.sub(r'(\"Edges\":)\\s*\\[\\[', r'\\1 [', cleaned_edges)\n",
        "    cleaned_edges = re.sub(r'\\]\\]', r']', cleaned_edges)  # Remove extra closing bracket\n",
        "\n",
        "    # Final wrap with a single curly brace to create a valid JSON object\n",
        "    cleaned_data = \"{\" + cleaned_edges + \"}\"\n",
        "\n",
        "    # Step 4: Convert to dictionary\n",
        "    try:\n",
        "        return json.loads(cleaned_data)\n",
        "    except json.JSONDecodeError as e:\n",
        "\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iLV4VkvLa9C"
      },
      "source": [
        "Extration of navigation instructions data from dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzQr-zZXKDdJ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "fixed =[508,\n",
        "        705,\n",
        "        786]\n",
        "\n",
        "#iterator\n",
        "#for i in range(500, 800):\n",
        "for i in fixed:\n",
        "    instruction = df['navigation_text'][i]\n",
        "    Instance_id = df['id'][i]\n",
        "\n",
        "    #Requesting to Chat GPT-4o###############################################################################\n",
        "    api_key = 'your_API_key'\n",
        "    data_structure = structure(instruction, api_key, shot_learning)\n",
        "\n",
        "    #Convert graph into a list of directories###############################################################3\n",
        "    converted_result = clean_and_convert(data_structure)\n",
        "    if converted_result is not None:\n",
        "        my_dictionary = {\n",
        "          \"Instance_id\": Instance_id,\n",
        "          \"Navigation_instruction\": instruction,\n",
        "          \"Graph\": converted_result,\n",
        "          }\n",
        "\n",
        "            # Define the filename for the JSON file\n",
        "        filename = '/content/dev_graph_lmm.json'\n",
        "\n",
        "            # Check if the file exists\n",
        "        if os.path.exists(filename):\n",
        "                try:\n",
        "                    # Load the existing content\n",
        "                    with open(filename, 'r') as file:\n",
        "                        content = file.read().strip()  # Read the content and strip whitespace\n",
        "                        if content:  # Check if not empty\n",
        "                            accumulated_data = json.loads(content)\n",
        "                        else:\n",
        "                            accumulated_data = []  # Initialize an empty list if the file is empty\n",
        "                except json.JSONDecodeError:\n",
        "                    print(\"Error decoding JSON. The file may be corrupted. Initializing a new list.\")\n",
        "                    accumulated_data = []  # Reset if thereâ€™s an error\n",
        "        else:\n",
        "                # If the file does not exist, initialize a new list\n",
        "          accumulated_data = []\n",
        "\n",
        "            # Append the new dictionary to the accumulated data\n",
        "        accumulated_data.append(my_dictionary)\n",
        "\n",
        "            # Convert accumulated_data to standard types\n",
        "        accumulated_data = convert_to_standard_types(accumulated_data)\n",
        "\n",
        "          # Save the updated data to the JSON file\n",
        "        with open(filename, 'w') as file:\n",
        "            json.dump(accumulated_data, file, indent=4)\n",
        "    else:\n",
        "        print(f\"{i},\")\n",
        "    time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg0wRVVQJdIF",
        "outputId": "bba26edd-3606-4b9d-cdd3-ee63c761a66b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
