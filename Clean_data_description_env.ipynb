{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import cv2\n",
        "import numpy as np\n",
        "import imageio\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "import openai\n",
        "import base64\n",
        "import requests\n",
        "import io"
      ],
      "metadata": {
        "id": "pQsPMPBsp54d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define folder paths and file paths\n",
        "input_file = '/content/dev_visual_description_raw.json'\n",
        "output_file = '/content/clean_file.json'\n",
        "final_output_file = '/content/dev_environment_description.json'\n",
        "\n",
        "colom_to_remove = [\n",
        "    \",,,,\",\n",
        "    \",,,\",\n",
        "    \",,\",\n",
        "    \", , , , ,\",\n",
        "    \", , , ,\",\n",
        "    \", , ,\",\n",
        "    \", ,\",\n",
        "    \",  \",\n",
        "]\n",
        "\n",
        "# Phrases to eliminate\n",
        "phrases_to_remove = [\n",
        "    \"\\n\",\n",
        "    \", mural.\",\n",
        "    \"\\n-\",\n",
        "    \"Visible places:\",\n",
        "    \"Identified places:\",\n",
        "    \"buildings name, signs (signs on walls or windows), specific descriptions of the environment, traffic signs, bus stops, bike parking, or specific stores\",\n",
        "    \"name of the place identified from navigation instruction\",\n",
        "    \"Building names, advertisements, and specific stores or restaurants\",\n",
        "    \"Buildings with signs for \",\n",
        "    \"specific descriptions of the environment\",\n",
        "    \"There are no identifiable building names\",\n",
        "    \"store/restaurant name\",\n",
        "    \"and specific stores\",\n",
        "    \"\\u2019\",\n",
        "    \"No specific names visible\",\n",
        "    \"not clearly visible in the image\",\n",
        "    \"sign not clearly visible in the image\",\n",
        "    \"- Intersection type:\",\n",
        "    \"Intersection type: \",\n",
        "    \"Intersections type\",\n",
        "    \"Intersections type\",\n",
        "    \"intersection type \",\n",
        "    \"intersections type \",\n",
        "    \"building names\",\n",
        "    \"red brick building\",\n",
        "    \"Red brick building\",\n",
        "    \"intersection appears to be a\",\n",
        "    \"name visible\",\n",
        "    \"Signs on buildings\",\n",
        "    \"Advertisements\",\n",
        "    \"Advertisement\",\n",
        "    \"advertisements\",\n",
        "    \"advertisement\",\n",
        "    \"visible\",\n",
        "    \"Building names\",\n",
        "    \"Market sign\",\n",
        "    \"Market signs\",\n",
        "    \"specific stores\",\n",
        "    \"name not identifiable\",\n",
        "    \"Intersection type\",\n",
        "    \"intersection type\",\n",
        "    \"not identifiable\",\n",
        "    \"- Specific signs: \",\n",
        "    \"- Specific stores: \",\n",
        "    \"- Landmark name: \",\n",
        "    \"- Buildings:\",\n",
        "    \"restaurant signs\",\n",
        "    \"buildings name\",\n",
        "    \"buildings names\",\n",
        "    \"building name\",\n",
        "    \"Building name\",\n",
        "    \"sign on building\",\n",
        "    \"signs on building\",\n",
        "    \"on building windows\",\n",
        "    \"on building window\",\n",
        "    \"signs on walls or windows\",\n",
        "    \"store/restaurant name\",\n",
        "    \"signs on windows\",\n",
        "    \"signs on walls\",\n",
        "    \"sign on the wall\",\n",
        "    \"sign on the walls\",\n",
        "    \"sign on window\",\n",
        "    \"on windows\",\n",
        "    \"sign on the window\",\n",
        "    \"sign on a building\",\n",
        "    \"signs on buildings\",\n",
        "    \"sign on building\",\n",
        "    \"restaurant sign\",\n",
        "    \"specific signs\",\n",
        "    \"landmark name\",\n",
        "    \"junction type\",\n",
        "    \"traffic signs\",\n",
        "    \"traffic sign\",\n",
        "    \"Traffic signs\",\n",
        "    \"Traffic sign\",\n",
        "    \"traffic signals\",\n",
        "    \"traffic signal\",\n",
        "    \"street signs\",\n",
        "    \"store sign\",\n",
        "    \"crosswalk sign\",\n",
        "    \"crosswalk signs\",\n",
        "    \"Crosswalk sign\",\n",
        "    \" store name\",\n",
        "    \"No specific names\\n \\n \\n \\n\",\n",
        "    \"descriptions of the environment\",\n",
        "    \"but there's\",\n",
        "    \"like \",\n",
        "    \"type \",\n",
        "    \"\\u201d\",\n",
        "    \"\\u201c\",\n",
        "    \"\\u014d\",\n",
        "    \"\\u00d4\",\n",
        "    \" name\",\n",
        "    \" \\n\",\n",
        "    \"/\",\n",
        "    \" .\",\n",
        "    \".\",\n",
        "    \";\",\n",
        "    \"\\ \",\n",
        "    \"\\\"\",\n",
        "    \" or\",\n",
        "    \" or \",\n",
        "    \"None\",\n",
        "    \"none\",\n",
        "    \"- Junction type: \",\n",
        "    \"- Junction type: \",\n",
        "    \"crosswalks\",\n",
        "    \"crosswalk\",\n",
        "    \":\",\n",
        "    \"on awnings\",\n",
        "    \"on awning\",\n",
        "    \"scaffoldings\",\n",
        "    \"scaffolding\",\n",
        "    \"Scaffoldings\",\n",
        "    \"Scaffolding\",\n",
        "    \"\\u70e4\\u8089\\u5e97 \",\n",
        "    \"specific store\",\n",
        "    \"on the right side\",\n",
        "    \"on the left\",\n",
        "    \"on the right\",\n",
        "    \"(s)\",\n",
        "    \"--\",\n",
        "    \"with signs in another language\",\n",
        "    \"in another language\",\n",
        "    \"environment description\",\n",
        "    \"buildings\",\n",
        "    \"()\",\n",
        "    \"There is not environment description\",\n",
        "    \", environment descriptions:\",\n",
        "    \"- Specific stores restaurant:\",\n",
        "    \"Specific\",\n",
        "    \"\\u2764\\ufe0f \",\n",
        "    \": \\u70e4\\u8089\\u5e97\",\n",
        "    \"with \",\n",
        "    \"- :\",\n",
        "    \"(\",\n",
        "    \")\",\n",
        "    \" s,\",\n",
        "    \"on the windows\",\n",
        "    \"outdoor dining\",\n",
        "    \"B\\u00d8\",\n",
        "    \"including\",\n",
        "    \"There is not environment description\",\n",
        "\n",
        "]\n",
        "\n",
        "# Define a dictionary for all the replacement rules\n",
        "replacements = {\n",
        "    \"bike parking\": \"Bike Rental\",\n",
        "    \"Bank\": \"bank\",\n",
        "    \"BANK\": \"bank\",\n",
        "    \"Market\": \"MARKET\",\n",
        "    \"market\": \"MARKET\",\n",
        "    \"Dunkin'\": \"Dunkin\",\n",
        "    \"stops\": \"stop\",\n",
        "    \"stop\": \"Stop\",\n",
        "    \"STOP sign\": \"STOP\",\n",
        "    \"STOP\": \"Stop sign\",\n",
        "    \"bus\": \"Bus\",\n",
        "    \"Dunkin\": \"Dunkin' Donuts\",\n",
        "    \"restaurants\": \"\",\n",
        "    \"restaurant\": \"\",\n",
        "    \"Restaurants\": \"\",\n",
        "    \"Restaurant\": \"\",\n",
        "    \"\\u1edf\": \"o\",\n",
        "    \"MARKET store\": \"MARKET\",\n",
        "    \"Chase bank\": \"Chase\",\n",
        "    \"Chase\": \"Chase bank\",\n",
        "    \"TD bank\": \"TD\",\n",
        "    \"Santander bank\": \"Santander\",\n",
        "    \"bank Santander\": \"Santander\",\n",
        "    \"Santander\": \"bank Santander\",\n",
        "    \"TD\": \"TD bank\",\n",
        "    \"intersection\": \"Intersection\",\n",
        "    \"MARKET\": \"Market store\",  # Replace all occurrences of MARKET\n",
        "    \"Intersection (4-way)\": \"4-way Intersection\",\n",
        "    \"signs\": \"sign\",\n",
        "    \"\\u00e9\": \"e \",  # Accent character replacement\n",
        "    \"3-way Intersection\": \"T-Intersection\",\n",
        "    \"VITAL store establishment\": \"Vital Climbing\",\n",
        "    \"VITAL\": \"Vital Climbing\",\n",
        "    \"CLIMBING\": \"Vital Climbing\",\n",
        "    \"bicycle parking\": \"Bike Rental\",\n",
        "    \"\\u2764\\ufe0f\": \"Love\",\n",
        "    \"scaffolding,\": \"\",  # Remove trailing commas\n",
        "    \", and\": \",\",\n",
        "    \" ,\": \",\",\n",
        "    \",\": \", \",\n",
        "    \"  \": \" \",\n",
        "    \"   \": \" \",\n",
        "}\n",
        "# Load JSON content\n",
        "with open(input_file, 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Recursive function to clean text in a dictionary or list\n",
        "def clean_text(obj):\n",
        "    if isinstance(obj, str):\n",
        "        # Remove lines that contain \"I'm sorry\" and replace phrases in phrases_to_remove with \"\"\n",
        "        lines = obj.splitlines()\n",
        "        filtered_lines = []\n",
        "        for line in lines:\n",
        "            if \"I'm\" not in line:  # Remove lines containing \"I'm sorry\"\n",
        "                # If the line contains \"Identified places:\", remove everything after it\n",
        "                if \"Identified places:\" in line:\n",
        "                    line = line.split(\"Identified places:\")[0].strip()  # Keep content before \"Identified places:\"\n",
        "                # Replace each phrase in phrases_to_remove with an empty string\n",
        "                for phrase in phrases_to_remove:\n",
        "                    line = line.replace(phrase, \"\")\n",
        "                for colom in colom_to_remove:\n",
        "                    line = line.replace(colom, \",\")\n",
        "                # Replace \"traffic light\" with \"intersection\"\n",
        "                # Define a dictionary for all the replacement rules\n",
        "                for key, value in replacements.items():\n",
        "                    line = line.replace(key, value)\n",
        "\n",
        "                line = line.strip(',').strip()\n",
        "                # Ensure that single commas alone are removed\n",
        "                if line != \",\":\n",
        "                    filtered_lines.append(line)\n",
        "\n",
        "        # Join back the remaining lines and return the cleaned string\n",
        "        return \"\".join(filtered_lines).strip(',')\n",
        "    elif isinstance(obj, list):\n",
        "        return [clean_text(item) for item in obj if item not in (\",\", \"\")]\n",
        "    elif isinstance(obj, dict):\n",
        "        return {key.strip(): clean_text(value) for key, value in obj.items() if value not in (\"\", None, \",\")}\n",
        "    return obj\n",
        "\n",
        "# Process the data\n",
        "cleaned_data = clean_text(data)\n",
        "\n",
        "# Save the initial cleaned data to a JSON file\n",
        "with open(output_file, 'w') as file:\n",
        "    json.dump(cleaned_data, file, indent=4)\n",
        "\n",
        "print(f\"Initial cleaned JSON data saved to: {output_file}\")\n",
        "\n",
        "# Reload the cleaned data from the JSON file\n",
        "with open(output_file, 'r') as file:\n",
        "    reloaded_data = json.load(file)\n",
        "\n",
        "# Function to remove empty keys\n",
        "def remove_empty_keys(obj):\n",
        "    if isinstance(obj, dict):\n",
        "        # Remove key-value pairs where value is empty string or None\n",
        "        return {key: remove_empty_keys(value) for key, value in obj.items() if value not in (\"\", None, \"signs\", \", signs\")}\n",
        "    elif isinstance(obj, list):\n",
        "        return [remove_empty_keys(item) for item in obj]\n",
        "    return obj  # Return non-dictionary/list objects unchanged\n",
        "\n",
        "# Remove keys with empty values\n",
        "final_cleaned_data = remove_empty_keys(reloaded_data)\n",
        "\n",
        "# Add \"Starting point\" to the first node's panoramic and \"Target\" to the last node's panoramic\n",
        "def add_start_and_target(data):\n",
        "    for instance in data:\n",
        "        # Loop through the Node Description of each instance\n",
        "        node_description = instance.get(\"Node Description\", {})\n",
        "\n",
        "        # Get the first and last node keys\n",
        "        node_keys = list(node_description.keys())\n",
        "\n",
        "        if node_keys:\n",
        "            # Modify the first node's panoramic\n",
        "            first_node_key = node_keys[0]\n",
        "            node_description[first_node_key][\"panoramic\"] = (\"Starting Point, \" +\n",
        "                node_description[first_node_key].get(\"panoramic\", \"\")\n",
        "            )\n",
        "\n",
        "            # Modify the last node's panoramic\n",
        "            last_node_key = node_keys[-1]\n",
        "            node_description[last_node_key][\"panoramic\"] = (\"Target, \"+\n",
        "                node_description[last_node_key].get(\"panoramic\", \"\")\n",
        "            )\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply the changes to the reloaded data\n",
        "final_cleaned_data = add_start_and_target(final_cleaned_data)\n",
        "\n",
        "# Save the final cleaned data to a new JSON file\n",
        "with open(final_output_file, 'w') as file:\n",
        "    json.dump(final_cleaned_data, file, indent=4)\n",
        "\n",
        "print(f\"Final cleaned JSON data with 'Starting point' and 'Target' added saved to: {final_output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlRuVCHawH_2",
        "outputId": "fa05ddde-6b02-47a1-cd6f-7cd5a7bd9a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial cleaned JSON data saved to: /content/clean_file.json\n",
            "Final cleaned JSON data with 'Starting point' and 'Target' added saved to: /content/dev_environment_description.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "# Define folder paths and file paths\n",
        "input_file = '/content/dev_environment_description.json'\n",
        "\n",
        "# Load JSON content\n",
        "with open(input_file, 'r') as file:\n",
        "    data_ck = json.load(file)\n",
        "\n",
        "# Function to combine keys into \"description\"\n",
        "def combine_keys(data):\n",
        "    for instance in data:\n",
        "        node_description = instance.get(\"Node Description\", {})\n",
        "        for node_id, node_data in node_description.items():\n",
        "            # Collect components for the description\n",
        "            description_parts = []\n",
        "\n",
        "            # Combine 'panoramic', 'Forward', and 'Backward' contents\n",
        "            description_parts.append(node_data.get(\"panoramic\", \"\"))\n",
        "            description_parts.append(node_data.get(\"Forward\", \"\"))\n",
        "            description_parts.append(node_data.get(\"Backward\", \"\"))\n",
        "\n",
        "            # Create the \"description\" key\n",
        "            description = \", \".join(filter(None, description_parts)).strip()\n",
        "\n",
        "            # Create a new ordered dictionary with 'description' first\n",
        "            ordered_node = OrderedDict()\n",
        "            ordered_node[\"description\"] = description\n",
        "\n",
        "            # Add remaining keys ('On the left' and 'On the right') as they are\n",
        "            for key in [\"On the left\", \"On the right\"]:\n",
        "                if key in node_data:\n",
        "                    ordered_node[key] = node_data[key]\n",
        "\n",
        "            # Update the node with the ordered dictionary\n",
        "            node_description[node_id] = ordered_node\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply the transformation\n",
        "transformed_data = combine_keys(data_ck)\n",
        "\n",
        "# Save the output to a file\n",
        "output_file = \"transformed_data.json\"\n",
        "with open(output_file, \"w\") as file:\n",
        "    json.dump(transformed_data, file, indent=4)\n",
        "\n",
        "print(f\"Transformed data saved to: {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtY-5r-p03yY",
        "outputId": "27c5b140-0a3c-4133-c43f-2a6071148e2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed data saved to: transformed_data.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load the provided JSON file\n",
        "file_path = \"/content/transformed_data.json\"  # Update with the correct file path\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Function to remove repeated places or landmarks in descriptions\n",
        "def clean_repeated_places(node_desc):\n",
        "    cleaned_desc = {}\n",
        "    for node_id, details in node_desc.items():\n",
        "        description_words = set(details[\"description\"].split(\", \"))\n",
        "\n",
        "        # Collect words from \"On the left\" and \"On the right\"\n",
        "        left_words = set(details.get(\"On the left\", \"\").split(\", \"))\n",
        "        right_words = set(details.get(\"On the right\", \"\").split(\", \"))\n",
        "        #forward_words = set(details.get(\"Forward\", \"\").split(\", \"))\n",
        "\n",
        "        # Remove words that appear in either \"On the left\" or \"On the right\"\n",
        "        cleaned_words = description_words - left_words - right_words# - forward_words\n",
        "\n",
        "        # Update description\n",
        "        cleaned_desc[node_id] = details.copy()\n",
        "        cleaned_desc[node_id][\"description\"] = \", \".join(cleaned_words)\n",
        "\n",
        "    return cleaned_desc\n",
        "\n",
        "# Apply cleaning function to all instances\n",
        "for instance in data:\n",
        "    instance[\"Node Description\"] = clean_repeated_places(instance[\"Node Description\"])\n",
        "\n",
        "# Save the cleaned data\n",
        "cleaned_file_path = \"/content/cleaned_transformed_data.json\"\n",
        "with open(cleaned_file_path, \"w\") as cleaned_file:\n",
        "    json.dump(data, cleaned_file, indent=4)\n",
        "\n",
        "print(f\"Cleaned data saved to {cleaned_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-u2HkQQQpyt",
        "outputId": "9f89ee33-9cf0-45e6-deab-a1396ede9932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned data saved to /content/cleaned_transformed_data.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import OrderedDict\n",
        "# Define folder paths and file paths\n",
        "input_file = '/content/cleaned_transformed_data.json'\n",
        "\n",
        "# Load JSON content\n",
        "with open(input_file, 'r') as file:\n",
        "    data_flat = json.load(file)\n",
        "\n",
        "# Function to flatten and generate the actions list\n",
        "def flatten_and_generate_actions(data):\n",
        "    for instance in data:\n",
        "        node_description = instance.get(\"Node Description\", {})\n",
        "        new_node_description = OrderedDict()  # To store flattened descriptions\n",
        "        actions = []  # To store the sequence of actions\n",
        "        counter = 1\n",
        "\n",
        "        # Process each node and add its description\n",
        "        for node_id, node_data in node_description.items():\n",
        "            # Add the main description, check if it is empty or None\n",
        "            description = node_data.get(\"description\", \"\").strip()  # Strip to handle spaces\n",
        "            if not description:\n",
        "                description = \"There is not environment description\"\n",
        "            new_node_description[str(counter)] = description\n",
        "            actions.append(\"description\")\n",
        "            counter += 1\n",
        "\n",
        "            # Add \"On the left\" if present\n",
        "            if \"On the left\" in node_data:\n",
        "                new_node_description[str(counter)] = node_data[\"On the left\"]\n",
        "                actions.append(\"On the left\")\n",
        "                counter += 1\n",
        "\n",
        "            # Add \"On the right\" if present\n",
        "            if \"On the right\" in node_data:\n",
        "                new_node_description[str(counter)] = node_data[\"On the right\"]\n",
        "                actions.append(\"On the right\")\n",
        "                counter += 1\n",
        "\n",
        "            # Add \"On front\" if present\n",
        "            #if \"Forward\" in node_data:\n",
        "             #   new_node_description[str(counter)] = node_data[\"Forward\"]\n",
        "              #  actions.append(\"In front\")\n",
        "               # counter += 1\n",
        "\n",
        "        # Update the instance with the new flattened structure and actions\n",
        "        instance[\"Node Description\"] = new_node_description\n",
        "        instance[\"actions\"] = actions\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply the transformation\n",
        "transformed_data = flatten_and_generate_actions(data_flat)\n",
        "\n",
        "# Save the output to a file\n",
        "output_file = \"flattened_with_stop_actions.json\"\n",
        "with open(output_file, \"w\") as file:\n",
        "    json.dump(transformed_data, file, indent=4)\n",
        "\n",
        "print(f\"Transformed data with 'Stop' action saved to: {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQCRAmfeNB25",
        "outputId": "4551d00d-517e-4106-9e48-17dd790ed740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed data with 'Stop' action saved to: flattened_with_stop_actions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Define folder paths and file paths\n",
        "input_file = '/content/flattened_with_stop_actions.json'\n",
        "\n",
        "# Load JSON content\n",
        "with open(input_file, 'r') as file:\n",
        "    data_open = json.load(file)\n",
        "\n",
        "def convert_actions(data):\n",
        "    # List to hold the transformed data\n",
        "    transformed_data = []\n",
        "\n",
        "    # Iterate over each instance in the data\n",
        "    for instance in data:\n",
        "        # Extract the Instance_id and Node Description\n",
        "        instance_id = instance.get(\"Instance_id\")\n",
        "        node_description = instance.get(\"Node Description\")\n",
        "        actions = instance.get(\"actions\", [])\n",
        "\n",
        "        # Initialize variables for tracking actions\n",
        "        converted_actions = []\n",
        "\n",
        "        # Get all indices of \"description\" actions\n",
        "        loc = [i + 1 for i, action in enumerate(actions) if action == \"description\"]\n",
        "\n",
        "        # Generate links based on actions\n",
        "        j = 0  # Track the current description node\n",
        "        for index, action in enumerate(actions):\n",
        "            if action == \"description\":\n",
        "                if j < len(loc) - 1:\n",
        "                    converted_actions.append({\n",
        "                        \"from\": loc[j],\n",
        "                        \"to\": loc[j + 1],\n",
        "                        \"action\": \"description\"\n",
        "                    })\n",
        "                j += 1  # Move to the next description node\n",
        "            elif action == \"On the left\":\n",
        "                converted_actions.append({\n",
        "                    \"from\": loc[j - 1],\n",
        "                    \"to\": index + 1,\n",
        "                    \"action\": \"On the left\"\n",
        "                })\n",
        "            elif action == \"On the right\":\n",
        "                converted_actions.append({\n",
        "                    \"from\": loc[j - 1],\n",
        "                    \"to\": index + 1,\n",
        "                    \"action\": \"On the right\"\n",
        "                })\n",
        "            #elif action == \"In front\":\n",
        "             #   converted_actions.append({\n",
        "              #      \"from\": loc[j - 1],\n",
        "               #     \"to\": index + 1,\n",
        "                #    \"action\": \"In front\"\n",
        "                #})\n",
        "\n",
        "        # Add the transformed instance to the result\n",
        "        transformed_instance = {\n",
        "            \"Instance_id\": instance_id,\n",
        "            \"Node Description\": node_description,\n",
        "            \"actions\": converted_actions\n",
        "        }\n",
        "        transformed_data.append(transformed_instance)\n",
        "\n",
        "    return transformed_data\n",
        "\n",
        "# Apply the transformation\n",
        "transformed_data = convert_actions(data_open)\n",
        "\n",
        "# Save the output to a file\n",
        "output_file = \"actions_file.json\"\n",
        "with open(output_file, \"w\") as file:\n",
        "    json.dump(transformed_data, file, indent=4)\n",
        "\n",
        "print(f\"Transformed data with actions saved to: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GSCqI2euiuS",
        "outputId": "61093e57-8186-4739-a341-4c6f407dbae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed data with actions saved to: actions_file.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Define file paths\n",
        "input_data_file = '/content/actions_file.json'\n",
        "directions_file = '/content/dev_visual_environment_directions.json'\n",
        "output_file = '/content/updated_environment_descriptions.json'\n",
        "\n",
        "# Load JSON data\n",
        "with open(input_data_file, 'r') as file:\n",
        "    action_data = json.load(file)\n",
        "\n",
        "with open(directions_file, 'r') as file:\n",
        "    direction_data = json.load(file)\n",
        "\n",
        "# Convert directions data to a dictionary for faster access\n",
        "directions_map = {item[\"Instance_id\"]: item[\"Directions\"] for item in direction_data}\n",
        "\n",
        "# Update action descriptions with corresponding directions\n",
        "for instance in action_data:\n",
        "    instance_id = instance[\"Instance_id\"]\n",
        "    if instance_id in directions_map:\n",
        "        directions = directions_map[instance_id]\n",
        "        direction_index = 0  # Initialize direction index\n",
        "        for action in instance[\"actions\"]:\n",
        "            if action[\"action\"] == \"description\":\n",
        "                if direction_index < len(directions):\n",
        "                    action[\"action\"] = directions[direction_index]\n",
        "                    direction_index += 1\n",
        "\n",
        "# Save the updated data\n",
        "with open(output_file, 'w') as file:\n",
        "    json.dump(action_data, file, indent=4)\n",
        "\n",
        "print(f\"Updated actions saved to: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzNK4MkDM1ox",
        "outputId": "29d84d5c-c922-4c4d-85d7-e2f8e177e3f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated actions saved to: /content/updated_environment_descriptions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load the provided JSON file\n",
        "file_path = \"/content/updated_environment_descriptions.json\"  # Update with the correct file path\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Function to remove duplicate places or landmarks in node descriptions\n",
        "def clean_node_descriptions(node_desc):\n",
        "    cleaned_desc = {}\n",
        "    for key, desc in node_desc.items():\n",
        "        unique_elements = list(dict.fromkeys(desc.split(\",\")))  # Remove duplicates while preserving order\n",
        "        cleaned_desc[key] = \",\".join(unique_elements)\n",
        "    return cleaned_desc\n",
        "\n",
        "# Apply cleaning function to all instances\n",
        "for instance in data:\n",
        "    instance[\"Node Description\"] = clean_node_descriptions(instance[\"Node Description\"])\n",
        "\n",
        "# Save the cleaned data\n",
        "cleaned_file_path = \"/content/cleaned_environment_descriptions.json\"\n",
        "with open(cleaned_file_path, \"w\") as cleaned_file:\n",
        "    json.dump(data, cleaned_file, indent=4)\n",
        "\n",
        "print(f\"Cleaned data saved to {cleaned_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxSTb8i-A_7v",
        "outputId": "20bbdbde-1756-45ce-9fcd-aa40a7fb1346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned data saved to /content/cleaned_environment_descriptions.json\n"
          ]
        }
      ]
    }
  ]
}